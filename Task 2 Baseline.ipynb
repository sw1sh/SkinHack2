{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_hdf('train_test.hdf', 'train')\n",
    "test = pd.read_hdf('train_test.hdf', 'test')\n",
    "\n",
    "ts_columns = ['motion', 'temperature', \n",
    "              'sweat_10', 'sweat_11', 'sweat_12', 'sweat_13', 'sweat_14', 'sweat_15', 'sweat_16',\n",
    "              'sweat_r0', 'sweat_r1', 'sweat_r2', 'sweat_r3', 'sweat_r4', 'sweat_r5', 'sweat_r6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_features(values):\n",
    "    if type(values[0]) == np.float64:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=values))\n",
    "    elif type(values[0]) == np.float:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[np.float64(v) for v in values]))\n",
    "    if type(values[0]) == np.int64:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=values))\n",
    "    elif type(values[0]) == str:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[v.encode() for v in values]))\n",
    "\n",
    "def value_feature(value):\n",
    "    if type(value) == np.float64:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "    elif type(value) == np.float:\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[np.float64(value)]))\n",
    "    elif type(value) == np.int64:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    elif type(value) == int:\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    elif type(value) == str:\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value.encode()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info = pd.read_excel('Infos.xlsx').set_index(['id', 'study'])\n",
    "info.sex.fillna('NaN', inplace=True)\n",
    "info.self_size.fillna('NaN', inplace=True)\n",
    "info.shirt_size.fillna('NaN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfrecords(data, filepath, is_train=True):\n",
    "    writer = tf.python_io.TFRecordWriter(filepath)\n",
    "    for _, g in tqdm_notebook(data.groupby(level=[0,1,2,3])):\n",
    "        cur_info = info.loc[_[0], _[2]]\n",
    "        feature = {'id': value_feature(_[0]), 'boardmac': value_feature(_[1]), \n",
    "                   'study': value_feature(_[2]), 'period': value_feature(_[3])}\n",
    "        feature.update({column: value_feature(cur_info[column])\n",
    "                   for column in ['sex', 'age', 'self_size', 'shirt_size', 'deodorant_left', 'deodorant_right']})\n",
    "        feature.update({'sequence_length': value_feature(g.shape[0])})\n",
    "        feature.update({column: value_features(g[column].values) for column in (ts_columns if is_train else ['motion', 'temperature'])})\n",
    "        feature.update({'timestamp': value_features([np.int64(dt.timestamp()) for dt in g['datetime'].dt.tz_localize('UTC').dt.to_pydatetime()])})\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "make_tfrecords(train, 'train.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22d34927596a4b1d8c223b0c36d4376c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "make_tfrecords(test, 'test.tfrecords', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "class Baseline:\n",
    "    \n",
    "    def __init__(self, filepath, batch_size, is_train=True):\n",
    "        with tf.Graph().as_default() as graph:\n",
    "\n",
    "            dataset = tf.data.TFRecordDataset(filepath).map(partial(self._parse_function, train=is_train))\n",
    "            if is_train:\n",
    "                dataset = dataset.shuffle(256)\n",
    "            dataset = dataset.padded_batch(batch_size, padded_shapes=dataset.output_shapes)\n",
    "            self.iterator = dataset.make_initializable_iterator()\n",
    "            self.example = self.iterator.get_next()\n",
    "\n",
    "            rnn_cell = keras.layers.LSTMCell(units=14)\n",
    "            rnn = keras.layers.RNN(rnn_cell, return_sequences=True)\n",
    "            t = tf.cast(self.example['timestamp'], tf.float32)\n",
    "            t_diff = t[:,1:] - t[:, :-1]\n",
    "            x = tf.stack([t_diff, self.example['motion'][:, 1:] / 960.0, self.example['temperature'][:, 1:] / 85.125], 2)\n",
    "            self.y_pred = rnn(x)\n",
    "            if is_train:\n",
    "                y_true = tf.stack([self.example[c][:, 1:] / 738600.0\n",
    "                                   for c in [c for c in ts_columns if c.startswith('sweat')]], 2)\n",
    "\n",
    "                self.loss = tf.reduce_mean(tf.reduce_mean(keras.losses.mean_squared_error(y_true, self.y_pred), 1), 0)\n",
    "\n",
    "                opt = tf.train.AdamOptimizer()\n",
    "                self.opt_op = opt.minimize(self.loss)\n",
    "\n",
    "            self.saver = tf.train.Saver()\n",
    "\n",
    "            self.graph = graph\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_function(self, example_proto, train=True):\n",
    "        features = {\n",
    "            'id': tf.FixedLenFeature((), tf.int64),\n",
    "            'boardmac': tf.FixedLenFeature((), tf.string),\n",
    "            'study': tf.FixedLenFeature((), tf.int64),\n",
    "            'period': tf.FixedLenFeature((), tf.int64),\n",
    "            'sex': tf.FixedLenFeature((), tf.string),\n",
    "            'age': tf.FixedLenFeature((), tf.float32),\n",
    "            'self_size': tf.FixedLenFeature((), tf.string),\n",
    "            'shirt_size': tf.FixedLenFeature((), tf.string),\n",
    "            'deodorant_left': tf.FixedLenFeature((), tf.int64),\n",
    "            'deodorant_right': tf.FixedLenFeature((), tf.int64),\n",
    "            'sequence_length': tf.FixedLenFeature((), tf.int64),\n",
    "            'timestamp': tf.FixedLenSequenceFeature((), tf.int64, allow_missing=True)\n",
    "        }\n",
    "        if train:\n",
    "            features.update({column: tf.FixedLenSequenceFeature((), tf.float32, allow_missing=True)\n",
    "                             for column in ts_columns})\n",
    "        else:\n",
    "            features.update({column: tf.FixedLenSequenceFeature((), tf.float32, allow_missing=True)\n",
    "                             for column in ['motion', 'temperature']})\n",
    "\n",
    "        return tf.parse_single_example(example_proto, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f088c901f61a4ec5a91757f700134a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "model = Baseline('train.tfrecords', 171, is_train=True)\n",
    "pb = tqdm_notebook(range(NUM_EPOCHS))\n",
    "\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #model.saver.restore(sess, 'model/model.ckpt')\n",
    "    \n",
    "    for epoch in pb:\n",
    "        sess.run(model.iterator.initializer)\n",
    "        while True:\n",
    "            try:\n",
    "                cur_loss, _ = sess.run([model.loss, model.opt_op])\n",
    "                pb.set_description(\"Current loss: %f\" % cur_loss)\n",
    "            except:\n",
    "                break\n",
    "        model.saver.save(sess, 'model/model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sweat_columns = [c for c in ts_columns if c.startswith('sweat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model = Baseline('test.tfrecords', 47, is_train=False)\n",
    "predictions = []\n",
    "with tf.Session(graph=model.graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    model.saver.restore(sess, 'model/model.ckpt')\n",
    "    \n",
    "    sess.run(model.iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            examples, preds = sess.run([model.example, model.y_pred])\n",
    "            for user_ID, boardmac, study, period, timestamp, seq_len, pred in zip(examples['id'], examples['boardmac'], examples['study'], examples['period'], \n",
    "                   examples['timestamp'], examples['sequence_length'], preds):\n",
    "                rows = {'user_ID': user_ID, 'boardmac': boardmac, 'study': study, 'period': period}\n",
    "               \n",
    "                rows.update({\n",
    "                    'timestamp': timestamp[:seq_len]\n",
    "                })\n",
    "                rows.update({\n",
    "                    c: np.pad(p[:seq_len], (max(seq_len - p.shape[0], 0), 0), 'constant') for p, c in zip(np.transpose(pred),sweat_columns) \n",
    "                })\n",
    "                predictions.append(pd.DataFrame(rows))\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['datetime'] = pd.to_datetime(submission['timestamp'], unit='s')\n",
    "submission['boardmac'] = submission.boardmac.str.decode('UTF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = submission.set_index(['user_ID', 'boardmac', 'study', 'period', 'datetime'])[sweat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_test = pd.read_hdf('private_data.hdf', 'true_test').set_index('datetime', append=True)[sweat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(submission.index == true_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553764573.16888249"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(true_test, submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
